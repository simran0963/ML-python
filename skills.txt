SKILLS:
    1. REGRESSION
    2. CLASSIFICATION
    3. CLUSTERING
    4. SCIKIT LEARN
    5. SCIPY

PROJECTS:
    1. CANCER DETECTION
    2. PREDICTIONG ECONOMIC TRENDS
    3. PREDICTING CUSTOMER CHURN
    4. RECOMMENDATION ENGINES
    
AQs:

Which Machine Learning  technique is proper for grouping of similar cases in a dataset, for example to find similar patients, or for customers
segmentation in a bank?
->clustering

Why Scikit is a proper library for Machine Learning (select all the options that are correct)?
->Scikit-learn is a free machine learning library that works with Numpy and Scipy.
->Scikit-learn has most of machine learning algorithms.

Which technique/s is/ are considered as supervised learning?
->classification, regression.


***********************************************************************************************************************************************
Assignment-I:

Supervised learning deals with unlabeled data, while unsupervised learning deals with labelled data.
False

Unsupervised learning deals with unlabeled data, and supervised learning deals with labelled data


Question 2
The "Regression" technique in Machine Learning is a group of algorithms that are used for:
Answer: 2.
1. Prediction of class/category of a case; for example, a cell is benign or malignant, or a customer will churn or not.


2. Predicting a continuous value; for example predicting the price of a house based on its characteristics.


3. Finding items/events that often co-occur; for example grocery items that are usually bought together by a customer.

Regression techniques are used for continuous variable prediction, whereas classification techniques handle dependent variables with discrete classes.


Question 3
When comparing Supervised with Unsupervised learning, is this sentence True or False?

In contrast to Supervised learning, Unsupervised learning has more models and more evaluation methods that can be used in order to ensure the outcome of the model is accurate.
False
Unsupervised learning has fewer models and evaluation methods than Supervised learning.

***********************************************************************************************************************************************

GRADED QUIZ 1

Question 1
In a dataset, what do the columns represent? features

Question 2
What is a major benefit of unsupervised learning over supervised learning?

Discover previously unknown information about the dataset.
    Being able to produce a prediction based on unlabelled data.
    Better evaluates the performance of a built model.
    Explore the relationship between features and the target.

Question 3
What’s the correct order for using a model?

    Clean the data, split the data into training and test sets, fit the model on the train set, evaluate model accuracy.
    xSplit the data into training and test sets, fit the model on the train set, evaluate model accuracy.
Clean the data, fit the model on the entire dataset, split the data into training and test sets, evaluate model accuracy.
    xSplit the data into the training and test sets, fit the model on the train set, clean the data, evaluate model accuracy.

Question 4
Which of the following is suitable for an unsupervised learning?

    xPredict house price based on location, house size, and number of rooms.
    xClassifying benign and malignant tumors using historical data on tumor shape, color, etc.
Segment customers into groups for discovering similar characteristics between them.
    xExamine the relationship between academic performance and level of in-class participation using observations that include a feature recording each student’s grade.

Question 5
The main purpose of the NumPy library is to: 

    Achieve scientific computations.
    Construct machine learning models.
Perform computations on arrays efficiently.
    Visualize results in 2D and 3D plots.

WEEK-2
    Model evaluation in regressio models:
    qs1.Which sentence is NOT TRUE about model accuracy?
        If a model is overly trained to the dataset, it may capture noise and produce a non-generalized model.
        Having a high training accuracy may result in an ‘over-fit’ of the data. 
    Doing a train and test on the same dataset will cause very high out-of-sample accuracy.
    
    qs2. In the context of regression, what is the error of a model?   
    The difference between the data points and the trend line generated by the algorithm  
        The difference between predicted values 
        "Out of sample" accuracy

    qs3. What is the best approach to find the parameter or coefficients for multiple linear regression, when we have very large dataset?
        Using linear algebra operations
    Using an optimization approach

    PRACTICE QUIZ REGRESSION:
    1. Which of the following is the meaning of "Out of Sample Accuracy" in the context of evaluation of models?
        "Out of Sample Accuracy" is the accuracy of an overly trained model (which may capture noise and produced a non-generalized model)
    "Out of Sample Accuracy" is the percentage of correct predictions that the model makes on data that the model has NOT been trained on.
        “Out of Sample Accuracy” is the accuracy of a model on all the data available.
        “Out of Sample Accuracy” is the percentage of correct predictions that the model makes using the test dataset.
    
    2. When should we use Multiple Linear Regression? (Select two)
    When we would like to predict impacts of changes in independent variables on a dependent variable.
        When there are multiple dependent variables
        When we would like to examine the relationship between multiple variables.
    When we would like to identify the strength of the effect that the independent variables have on a dependent variable. 
    
    3. Which sentence is TRUE about linear regression?
        A linear relationship is necessary between the independent and dependent variables as well as in between independent variables.
        Multiple linear regression requires a linear relationship between the predictors and the response, but simple linear regression does not.
        Simple linear regression requires a linear relationship between the predictor and the response, but multiple linear regression does not.
    A linear relationship is necessary between the independent variables and the dependent variable.

    GRADED QUIZ : REGRESSION
    1. What are the requirements for independent and dependent variables in regression?
        Independent variables must be continuous. Dependent variables can be either categorical or continuous.
        Independent and dependent variables can be either categorical or continuous. 
    Independent variables can be either categorical or continuous. Dependent variables must be continuous.
        Independent and dependent variables must be continuous.
    
    2. The key difference between simple and multiple regression is:
    To estimate a single dependent variable, simple regression uses one independent variable whereas multiple regression uses multiple.
        Simple regression assumes a linear relationship between variables, whereas this assumption is not necessary for multiple regression.
        Simple linear regression compresses multidimensional space into one dimension.
        Multiple linear regression introduces polynomial features. 

    3. Recall that we tried to predict CO2 emission with car information. Say that now we can describe the relationship as: CO2_emission = 130 - 2.4*cylinders + 8.3*fuel_consumption. What is TRUE of this relationship? 
    When “cylinders” decreases by 1 while fuel_consumption remains constant, CO2_emission increases by 2.4 units.
        When “cylinders” increases by 1 while fuel_consumption remains constant, CO2_emission increases by 2.4 units.
        Since the coefficient for “fuel_consumption” is greater than that for “cylinders”, “fuel_consumption” has higher impact on CO2_emission.
        When both “cylinders” and “fuel_consumption” increase by 1 unit, CO2_emission decreases. 

    4. What could be the cause of a model yielding high training accuracy and low out-of-sample accuracy?
        The model is training on a small training set, so it is underfitting.
        The model is training on a small training set, so it is overfitting.
    The model is training on the entire dataset, so it is overfitting.
        The model is training on the entire dataset, so it is underfitting.

    5. Multiple Linear Regression is appropriate for:
        Predicting the sales amount based on month.
    Predicting tomorrow’s rainfall amount based on the wind speed and temperature.
        Predicting whether a drug is effective for a patient based on her characteristics.

WEEK-3
    What is a multi-class classifier?
        A classifier that can predict multiple fields with many discrete values. 
        A classifier that can predict a field with two discrete values, such as ”Defaulter" or "Not Defaulter”. 
    A classifier that can predict a field with multiple discrete values, such as ”DrugA", ”DrugX" or "DrugY”. 

    Which of the following statements are TRUE about kNN?
    The kNN algorithm is a classification algorithm.
    The kNN algorithm classify cases based on their similarity to other cases. 
        The kNN algorithm works only with Euclidian distance.
            The bigger K is in KNN, the accuracy of the algorithm is better. 
    
    Which one is the ideal classifier?
    The classifier with F1-score close to one.
        The classifier with LogLoss close to one.
        The classifier with Jaccard-index close to zero.

    Which of the following sentences is NOT TRUE about Decision Tree?
        Decision Trees are built by splitting the training set into distinct nodes
    A Decision Tree is a type of clustering  approach that can predict the class of a group, for example, DrugA or DrugB.
        One node in a Decision Tree contains all of or most of, one category of the data.
    
    What is the meaning of Entropy in Decision Tree?
    The entropy in a node is the amount of information disorder calculated in each node.
        The entropy in a node is the number of similar data in that node. 
        The entropy in a node is the weighted information in its parent node.

    Assessment:
    Which one is TRUE about the kNN algorithm?
        kNN is a classification algorithm that takes a bunch of unlabelled points and uses them to learn how to label other points.
        The most similar point in kNN is the one with the smallest distance averaged across all normalized features.
        kNN calculates similarity by measuring how close the two data points’ response values are.
    kNN algorithm can be used to estimate values for a continuous target. 

    If the information gain of the tree by using attribute A is 0.3, what can we infer?
        Entropy in the decision tree increases by 0.3 if we make this split.
        By making this split, we increase the randomness in each child node by 0.3.
        Compared to attribute B with 0.65 information gain, attribute A should be selected first for splitting.
    The entropy of a tree before split minus weighted entropy after split by attribute A is 0.3.

    When we have a value of K for KNN that’s too small, what will the model most likely look like?
        The model will have high accuracy on the test set.
    The model will be highly complex and captures too much noise.
        The model will have high out-of-sample accuracy.
        The model will be overly simple and does not capture enough noise.

    Graded assessment:
    
Coursera
Machine Learning with Python
Week 3
Graded Quiz: Classification
Graded Quiz: Classification
Quiz15 minutes • 15 min
Submit your assignment
Due April 30, 11:59 PM ISTApr 30, 11:59 PM IST
Attempts 32 every 24 hours
Receive grade
To Pass 60% or higher
Your grade
-Not available

Graded Quiz: Classification
Graded Quiz. • 15 min. • 5 total points available.5 total points

    DueApr 30, 11:59 PM IST
    1. What can we infer about our kNN model when the value of K is too big?
            The model will be too complex and not interpretable.
            The model will capture a lot of noise as a result of overfitting.
        The model is overly generalized and underfitted to the data. 
            The training accuracy will be high, while the out-of-sample accuracy will be low.

    2. When splitting data into branches for a decision tree, what kind of feature is favored and chosen first?
            The feature with the greatest number of categories.
            The feature that splits the data equally into groups.
            The feature that increases entropy in the tree nodes.
        The feature that increases purity in the tree nodes.

    3. What is the relationship between entropy and information gain?
            High entropy and high information gain is desired.
            High entropy and low information gain is desired. 
            When information gain decreases, entropy decreases.
        When information gain increases, entropy decreases.

    4. Predicting whether a customer responds to a particular advertising campaign or not is an example of what?
        Classification problem
            Machine learning
            Regression
            None of the above

    5. For a new observation, how do we predict its response value (categorical) using a KNN model with k=5?
        Take majority vote among 5 points whose features are closest to the new observation.
            Form 5 clusters and assign the new observation to the most similar cluster, taking the mean value as prediction.
            Take the average among 5 points whose features are closest to the new observation.
            Take the majority vote among 5 points who are the most similar to each other.

WEEK - 4
    Logistic Regresion
    Which of the following sentences are TRUE about Logistic Regression?
    Logistic regression is analogous to linear regression but takes a categorical/discrete target field instead of a numeric one.    
    Logistic Regression measures the probability of a case belonging to a specific class.
    Logistic Regression can be used to understand the impact of a feature on a dependent variable.
    All are True

    What is difference between Linear Regression vs Logistic Regression, in solving a classification problem?
    Linear Regression cannot properly measure the probability of a case belonging to a class.
        Linear Regression is very slow in estimating the parameters of the model
        Linear Regression cannot handle large datasets.

    What is "gradient descent" in training process?
    A technique to use derivative of a cost function to change the parameter values, to minimize the cost.
        A technique to calculate the cost of logistic regression.
        A technique to initialize the parameters in training process.
    
    What is the meaning of "Kernelling" in SVM?
        Finding a hyperplane in such a way that increase the dimensionality of a dataset.
    Mapping data into a higher dimensional space, in such a way that can change a linearly inseparable dataset into a linearly separable dataset.
        A function to reduce the dimensionality of a dataset in SVM.
    
    PRACTICE QUIZ
    Which of the following examples is/are a sample application of Logistic Regression? (select three)
    Likelihood of a homeowner defaulting on a mortgage.
    Customer's propensity to purchase a product or halt a subscription in marketing applications.
    The probability that a person has a heart attack within a specified time period using person's age and sex.
        Estimating the blood pressure of a patient based on her symptoms and biographical data.

    Which of the following statements comparing linear and logistic regressions is TRUE?
        In this course, linear regression minimizes the mean absolute error, while logistic regression minimizes the mean squared error.
        Both linear and logistic regression can be used to predict categorical responses and attain a point’s likelihood of belonging to each class.
        Independent variables in linear regression can be continuous or categorical, but can only be categorical in logistic regression.
    Linear regression is used for a continuous target whereas logistic regression is more suitable for a categorical target.

    How are gradient descent and learning rate used in logistic regression? 
        Gradient descent will minimize learning rate to minimize the cost in fewer iterations.
        We want to minimize the cost by maximizing the learning rate value.
    Gradient descent specifies the steps to take in the current slope direction, learning rate is the step length.
        Gradient descent takes increasingly bigger steps towards the minimum with each iteration.
    
    GRADED ASSESSMENT 
    1. Which option lists the steps of training a logistic regression model in the correct order?

    1. Use the cost function on the training set.

    2. Update weights with new parameter values.

    3. Calculate cost function gradient.

    4. Initialize the parameters.

    5. Repeat until specified cost or iterations reached.
    4, 1, 3, 2, 5 

    2. What is the objective of SVM in terms of hyperplanes?
        Find the hyperplane of the lowest dimension.
        Choose the hyperplane that’s closest to one of the two classes.
        Minimize the distance between hyperplane and the support vectors.
    Choose the hyperplane that represents the largest margin between the two classes.

    3. Logistic regression is used to predict the probability of a:
        Numerical independent variable
        Numerical dependent variable
    Categorical dependent variable
        ­Categorical independent variable
    
    4. In which cases would we want to consider using SVM?
        When we desire efficiency when using large datasets.
        When we want multiple decision boundaries with varying weights.
        When we desire probability estimates for each class.
    When mapping the data to a higher dimensional feature space can better separate classes.

    5. What is a disadvantage of one-vs-all classification?
    There’s an ambiguous region where multiple classes are valid outputs.
        It cannot output probability estimates of classes.
        It requires more models to be created compared to one-vs-one.
        It does not handle two-class classification well.

    WEEK - 5
    KMEANS CLUSTERING
    What is the objective of k-means? 
    To form clusters in such a way that similar samples go into a cluster, and dissimilar samples fall into different clusters. 
    To minimize the “intra cluster” distances and maximize the “inter-cluster” distances. 
    To divide the data into non-overlapping clusters without any cluster-internal structure

    UNGRADED ASSESSMENT
    Which of the following is an application of clustering?
    Customer segmentation
        Sales prediction
        Customer churn prediction
        Price estimation
    
    Which approach can be used to calculate dissimilarity of objects in clustering?
        Cosine similarity
        Minkowski distance
        Euclidian distance
    All of the above

    How is a center point (centroid) picked for each cluster in k-means upon initialization? (select two)
        We can randomly choose some observations out of the data set and use these observations as the initial means.
        We can select it through correlation analysis.
        We can create some random points as centroids of the clusters.
    We select the k points closest to the mean/median of the entire dataset.

    GRADED ASSESSMENT
    1. The objective of k-means clustering is:
        Maximize the number of correctly classified data points
        Minimize the cost function via gradient descent
    Separate dissimilar samples and group similar ones
        Yield the highest out of sample accuracy

    2. Which option correctly orders the steps of k-means clustering?
        1. Re-cluster the data points
        2. Choose k random observations to calculate each cluster’s mean
        3. Update centroid to take cluster mean
        4. Repeat until centroids are constant
        5. Calculate data point distance to centroids
    2 5 3 1 4

    3. How can we gauge the performance of a k-means clustering model when ground truth is not available?
        Determine the prediction accuracy on the test set.
        Calculate the R-squared value to measure model fit.
        Calculate the number of incorrectly classified observations in the training set.
    Take the average of the distance between data points and their cluster centroids.

    4. When the parameter K for k-means clustering increases, what happens to the error?
    It will decrease because distance between data points and centroid will decrease.
        It might increase or decrease depending on if data points are closer to the centroid.
    chat gpt wrong: It will decrease because the data points are less possible to be in the wrong cluster.
        It will increase because incorrectly classified points are further from the correct centroid.

    5. Which of the following is true for partition-based clustering but not hierarchical nor density-based clustering algorithms?
    chat gpt says this but is wrong there: Partition-based clustering can handle spatial clusters and noisy data.
        Partition-based clustering produces arbitrary shaped clusters.
    Partition-based clustering produces sphere-like clusters.   
        Partition-based clustering is a type of unsupervised learning algorithm.

    